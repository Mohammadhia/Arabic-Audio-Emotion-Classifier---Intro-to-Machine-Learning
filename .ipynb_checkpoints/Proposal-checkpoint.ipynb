{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mohamad Aboufoul"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem and Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this project, I was interested in developing an intelligent system that could use data regarding audio in order to make inferences regarding it. I searched through some data bases, particularly on Kaggle, to get some idea of what information was available and what features are typically examined when working with audio data. \n",
    "\n",
    "I ended up finding a dataset on Arabic audio, called the “Arabic Natural Audio Dataset”, on Kaggle, posted by the user “SamiraKlaylat”. On it, information was extracted from speakers from eight videos, which were then further divided into single lines per speaker, resulting in 1383 samples. The goal of this dataset was to determine the emotion associated with a given input of speech, which is why each sample includes an emotion feature, which is classified into either “happy”, “surprised”, or “angry” based on numerous features extracted from each audio recording.\n",
    "\n",
    "There are twenty-five main acoustic features in this dataset: the intensity, the zero crossing rates, the Mel-frequency cepstral coefficients (MFCC 1-12; hence, 12 features), the fundamental frequency (F0), the fundamental frequency envelope (F0 envelope), the probability of voicing, and the LSP frequencies (0-7; hence, 8 features). On all of these features, nineteen statistical functions were applied, as well as delta coefficients on each language learning disability (LLD). However, if including the latter statistical functions and delta coefficients, the data set ends up having 950 features!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Steps and Approaches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this project, I believe using the first 25 features should be sufficient in developing a classifier that predicts whether or not a given audio sample of someone speaking Arabic is “happy”, “angry”, or “surprised”. I believe that using a 5-fold cross-validation on the dataset will work in developing a proper model, though there are many aspects that I am not certain of in the features. For example, I have never heard of the Mel-frequency cepstral coefficients, and I’m not entirely sure if they are useful in such a classifier. Looking at the dataset as of now, I believe that using the mean value for each feature will suffice. Though, perhaps using the normalized version of the data will be better for training the model.\n",
    "\n",
    "To proceed with developing a classifier, I believe I will have to use multi-class output, but I will probably have to employ as many kinds as possible in order to build the best possible model. I am still not entirely sure of how I will do so, nor if I will have to exclude some features if they produce noise in the model. However, I believe that after further progressing through this course, I will have a clearer vision for what steps to take. I will definitely have to consult with the Professor and TA when I run into roadblocks, which is almost imminent."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Timeline, Questions to be answered, and Expectations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The timeline for this project will of course depend on how quickly I learn the appropriate means of building classifiers on such datasets. Since it all the information is conveniently stored in csv files at https://www.kaggle.com/suso172/arabic-natural-audio-dataset/data, I should only have to worry about what features to remove or normalize, and which kind of classification algorithm will work best.\n",
    "\n",
    "I will be working alone on this assignment, and I hope to have a clear understanding of what features and algorithms to use by the beginning of November. I hope that this assignment will help answer the questions regarding what aspects of audio and linguistics are the best predictors of human emotion. Perhaps it will also answer some questions regarding whether or not individual samples of speech are truly bound to one emotion at a time. Maybe different emotions can be conveyed in the same linguistic output simultaneously.\n",
    "\n",
    "Finally, I expect to learn a great deal about the various aspects of linguistics as a whole through this project. Clearly, I have a lot to learn since I’m not familiar with most of the features that were listed above. I also expect to be able to use what I learn from this project to conduct other speech related machine learning projects on my own in the future. I hope that I can be successful in this endeavor as a whole."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
